{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "下面是训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Collecting tensorflow==1.5\n",
      "  Downloading http://pypi.doubanio.com/packages/34/96/11f048eca7b4d6da3084ca49c636b9e720e9dd1483c0c4e9ba3cf5037564/tensorflow-1.5.0-cp36-cp36m-win_amd64.whl (31.1 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\anaconda3\\lib\\site-packages (from tensorflow==1.5) (0.29.0)\n",
      "Collecting tensorflow-tensorboard<1.6.0,>=1.5.0\n",
      "  Downloading http://pypi.doubanio.com/packages/cc/fa/91c06952517b4f1bc075545b062a4112e30cebe558a6b962816cb33efa27/tensorflow_tensorboard-1.5.1-py3-none-any.whl (3.0 MB)\n",
      "Collecting absl-py>=0.1.6\n",
      "  Downloading http://pypi.doubanio.com/packages/23/47/835652c7e19530973c73c65e652fc53bd05725d5a7cf9bb8706777869c1e/absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: numpy>=1.12.1 in e:\\anaconda3\\lib\\site-packages (from tensorflow==1.5) (1.19.5)\n",
      "Collecting protobuf>=3.4.0\n",
      "  Downloading http://pypi.doubanio.com/packages/48/f1/49cc17101260e9651e9daab0afc8f43382e8e8d9262ae13d406e27ee83e8/protobuf-3.17.3-cp36-cp36m-win_amd64.whl (910 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in e:\\anaconda3\\lib\\site-packages (from tensorflow==1.5) (1.10.0)\n",
      "Collecting html5lib==0.9999999\n",
      "  Using cached html5lib-0.9999999-py3-none-any.whl\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading http://pypi.doubanio.com/packages/6e/33/1ae0f71395e618d6140fbbc9587cc3156591f748226075e0f7d6f9176522/Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting bleach==1.5.0\n",
      "  Downloading http://pypi.doubanio.com/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in e:\\anaconda3\\lib\\site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5) (0.12.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading http://pypi.doubanio.com/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "  Downloading http://pypi.doubanio.com/packages/a0/34/4d6b7e3044044e89eaa25ed5395656cc351163c625fda0656d2729de399f/Markdown-3.3.2-py3-none-any.whl (95 kB)\n",
      "  Downloading http://pypi.doubanio.com/packages/7a/2e/d769892bfb09144ad79ef525de0cb1765382e012cdd31aa117bef2ca7f66/Markdown-3.3.1-py3-none-any.whl (95 kB)\n",
      "  Downloading http://pypi.doubanio.com/packages/0e/ee/173f66a1954046debff7f4199cc826fc29d9e8521e1ae7a1c9d2bf858ea1/Markdown-3.3-py3-none-any.whl (94 kB)\n",
      "  Downloading http://pypi.doubanio.com/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "  Downloading http://pypi.doubanio.com/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: setuptools>=36 in e:\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5) (36.5.0.post20170921)\n",
      "Installing collected packages: html5lib, protobuf, markdown, bleach, tensorflow-tensorboard, absl-py, tensorflow\n",
      "  Attempting uninstall: html5lib\n",
      "    Found existing installation: html5lib 0.999999999\n",
      "    Uninstalling html5lib-0.999999999:\n",
      "      Successfully uninstalled html5lib-0.999999999\n",
      "  Attempting uninstall: bleach\n",
      "    Found existing installation: bleach 2.0.0\n",
      "    Uninstalling bleach-2.0.0:\n",
      "      Successfully uninstalled bleach-2.0.0\n",
      "Successfully installed absl-py-0.13.0 bleach-1.5.0 html5lib-0.9999999 markdown-3.2.1 protobuf-3.17.3 tensorflow-1.5.0 tensorflow-tensorboard-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Collecting keras==2.1.6\n",
      "  Downloading http://pypi.doubanio.com/packages/54/e8/eaff7a09349ae9bd40d3ebaf028b49f5e2392c771f294910f75bb608b241/Keras-2.1.6-py2.py3-none-any.whl (339 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in e:\\anaconda3\\lib\\site-packages (from keras==2.1.6) (1.19.5)\n",
      "Requirement already satisfied: h5py in e:\\anaconda3\\lib\\site-packages (from keras==2.1.6) (2.7.0)\n",
      "Requirement already satisfied: pyyaml in e:\\anaconda3\\lib\\site-packages (from keras==2.1.6) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\administrator\\appdata\\roaming\\python\\python36\\site-packages (from keras==2.1.6) (1.5.4)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda3\\lib\\site-packages (from keras==2.1.6) (1.10.0)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:53:12,925 [INFO] <ipython-input-1-de0dd4b77245>/main | Looking for fbank features [.npy] files in audio/LibriSpeechSamples/train-clean-100-npy/.\n",
      "Found 0000900 files with 00010 different speakers.\n",
      "2021-07-06 16:53:13,273 [INFO] <ipython-input-1-de0dd4b77245>/main | num_frames = 160\n",
      "2021-07-06 16:53:13,275 [INFO] <ipython-input-1-de0dd4b77245>/main | batch size: 96\n",
      "2021-07-06 16:53:13,278 [INFO] <ipython-input-1-de0dd4b77245>/main | input shape: (160, 64, 1)\n",
      "2021-07-06 16:53:13,281 [INFO] <ipython-input-1-de0dd4b77245>/main | x.shape : (96, 160, 64, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv64-s (Conv2D)               (None, 80, 32, 64)   1664        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv64-s_bn (BatchNormalization (None, 80, 32, 64)   256         conv64-s[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 80, 32, 64)   0           conv64-s_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "res1_0_branch_2a (Conv2D)       (None, 80, 32, 64)   36928       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res1_0_branch_2a_bn (BatchNorma (None, 80, 32, 64)   256         res1_0_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 80, 32, 64)   0           res1_0_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res1_0_branch_2b (Conv2D)       (None, 80, 32, 64)   36928       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res1_0_branch_2b_bn (BatchNorma (None, 80, 32, 64)   256         res1_0_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 80, 32, 64)   0           res1_0_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 80, 32, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_1_branch_2a (Conv2D)       (None, 80, 32, 64)   36928       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res1_1_branch_2a_bn (BatchNorma (None, 80, 32, 64)   256         res1_1_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 80, 32, 64)   0           res1_1_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res1_1_branch_2b (Conv2D)       (None, 80, 32, 64)   36928       lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res1_1_branch_2b_bn (BatchNorma (None, 80, 32, 64)   256         res1_1_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 80, 32, 64)   0           res1_1_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 80, 32, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res1_2_branch_2a (Conv2D)       (None, 80, 32, 64)   36928       lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res1_2_branch_2a_bn (BatchNorma (None, 80, 32, 64)   256         res1_2_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 80, 32, 64)   0           res1_2_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res1_2_branch_2b (Conv2D)       (None, 80, 32, 64)   36928       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res1_2_branch_2b_bn (BatchNorma (None, 80, 32, 64)   256         res1_2_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 80, 32, 64)   0           res1_2_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 80, 32, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv128-s (Conv2D)              (None, 40, 16, 128)  204928      lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv128-s_bn (BatchNormalizatio (None, 40, 16, 128)  512         conv128-s[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 40, 16, 128)  0           conv128-s_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2_0_branch_2a (Conv2D)       (None, 40, 16, 128)  147584      lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res2_0_branch_2a_bn (BatchNorma (None, 40, 16, 128)  512         res2_0_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 40, 16, 128)  0           res2_0_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2_0_branch_2b (Conv2D)       (None, 40, 16, 128)  147584      lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "res2_0_branch_2b_bn (BatchNorma (None, 40, 16, 128)  512         res2_0_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 40, 16, 128)  0           res2_0_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 40, 16, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2_1_branch_2a (Conv2D)       (None, 40, 16, 128)  147584      lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_1_branch_2a_bn (BatchNorma (None, 40, 16, 128)  512         res2_1_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 40, 16, 128)  0           res2_1_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2_1_branch_2b (Conv2D)       (None, 40, 16, 128)  147584      lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_1_branch_2b_bn (BatchNorma (None, 40, 16, 128)  512         res2_1_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 40, 16, 128)  0           res2_1_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 40, 16, 128)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2_2_branch_2a (Conv2D)       (None, 40, 16, 128)  147584      lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_2_branch_2a_bn (BatchNorma (None, 40, 16, 128)  512         res2_2_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 40, 16, 128)  0           res2_2_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res2_2_branch_2b (Conv2D)       (None, 40, 16, 128)  147584      lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2_2_branch_2b_bn (BatchNorma (None, 40, 16, 128)  512         res2_2_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 40, 16, 128)  0           res2_2_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 40, 16, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv256-s (Conv2D)              (None, 20, 8, 256)   819456      lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv256-s_bn (BatchNormalizatio (None, 20, 8, 256)   1024        conv256-s[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 20, 8, 256)   0           conv256-s_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3_0_branch_2a (Conv2D)       (None, 20, 8, 256)   590080      lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_0_branch_2a_bn (BatchNorma (None, 20, 8, 256)   1024        res3_0_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 20, 8, 256)   0           res3_0_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3_0_branch_2b (Conv2D)       (None, 20, 8, 256)   590080      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_0_branch_2b_bn (BatchNorma (None, 20, 8, 256)   1024        res3_0_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 20, 8, 256)   0           res3_0_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 20, 8, 256)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3_1_branch_2a (Conv2D)       (None, 20, 8, 256)   590080      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_1_branch_2a_bn (BatchNorma (None, 20, 8, 256)   1024        res3_1_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 20, 8, 256)   0           res3_1_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3_1_branch_2b (Conv2D)       (None, 20, 8, 256)   590080      lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_1_branch_2b_bn (BatchNorma (None, 20, 8, 256)   1024        res3_1_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 20, 8, 256)   0           res3_1_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 20, 8, 256)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3_2_branch_2a (Conv2D)       (None, 20, 8, 256)   590080      lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_2_branch_2a_bn (BatchNorma (None, 20, 8, 256)   1024        res3_2_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 20, 8, 256)   0           res3_2_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res3_2_branch_2b (Conv2D)       (None, 20, 8, 256)   590080      lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res3_2_branch_2b_bn (BatchNorma (None, 20, 8, 256)   1024        res3_2_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 20, 8, 256)   0           res3_2_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 20, 8, 256)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv512-s (Conv2D)              (None, 10, 4, 512)   3277312     lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv512-s_bn (BatchNormalizatio (None, 10, 4, 512)   2048        conv512-s[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 10, 4, 512)   0           conv512-s_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res4_0_branch_2a (Conv2D)       (None, 10, 4, 512)   2359808     lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4_0_branch_2a_bn (BatchNorma (None, 10, 4, 512)   2048        res4_0_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 10, 4, 512)   0           res4_0_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4_0_branch_2b (Conv2D)       (None, 10, 4, 512)   2359808     lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4_0_branch_2b_bn (BatchNorma (None, 10, 4, 512)   2048        res4_0_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 10, 4, 512)   0           res4_0_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 10, 4, 512)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4_1_branch_2a (Conv2D)       (None, 10, 4, 512)   2359808     lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4_1_branch_2a_bn (BatchNorma (None, 10, 4, 512)   2048        res4_1_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 10, 4, 512)   0           res4_1_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4_1_branch_2b (Conv2D)       (None, 10, 4, 512)   2359808     lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4_1_branch_2b_bn (BatchNorma (None, 10, 4, 512)   2048        res4_1_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 4, 512)   0           res4_1_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 10, 4, 512)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4_2_branch_2a (Conv2D)       (None, 10, 4, 512)   2359808     lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4_2_branch_2a_bn (BatchNorma (None, 10, 4, 512)   2048        res4_2_branch_2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 10, 4, 512)   0           res4_2_branch_2a_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "res4_2_branch_2b (Conv2D)       (None, 10, 4, 512)   2359808     lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res4_2_branch_2b_bn (BatchNorma (None, 10, 4, 512)   2048        res4_2_branch_2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 10, 4, 512)   0           res4_2_branch_2b_bn[0][0]        \n",
      "                                                                 lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 10, 4, 512)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Lambda)                (None, 10, 2048)     0           lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average (Lambda)                (None, 2048)         0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "affine (Dense)                  (None, 512)          1049088     average[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ln (Lambda)                     (None, 512)          0           affine[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 24,185,728\n",
      "Trainable params: 24,172,288\n",
      "Non-trainable params: 13,440\n",
      "__________________________________________________________________________________________________\n",
      "2021-07-06 16:53:16,138 [INFO] <ipython-input-1-de0dd4b77245>/main | None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:53:16,184 [INFO] <ipython-input-1-de0dd4b77245>/main | Found checkpoint [checkpoints\\model_17200_3.43310.h5]. Resume from here...\n",
      "加载了模型 checkpoints\\model_17200_3.43310.h5\n",
      "2021-07-06 16:53:17,989 [INFO] <ipython-input-1-de0dd4b77245>/main | [DONE]\n",
      "model_build_time 4.763998746871948\n",
      "2021-07-06 16:53:18,049 [INFO] <ipython-input-1-de0dd4b77245>/main | Starting training...\n",
      "get batch time 0.0s\n",
      "forward process time 1.28e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.097s\n",
      "select_batch_time: 128.38404321670532\n",
      "2021-07-06 16:55:26,436 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17200\n",
      "2021-07-06 16:56:34,468 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 68.03s by the network, training loss = 1.063816785812378.\n",
      "Found 0000900 files with 00010 different speakers.\n",
      "2021-07-06 16:58:11,460 [INFO] <ipython-input-1-de0dd4b77245>/main | test training data EER = 0.111, F-measure = 0.800, Accuracy = 0.993 \n",
      "Found 0000900 files with 00010 different speakers.\n",
      "2021-07-06 16:59:48,417 [INFO] <ipython-input-1-de0dd4b77245>/main | == Testing model after batch #17200\n",
      "2021-07-06 16:59:48,419 [INFO] <ipython-input-1-de0dd4b77245>/main | EER = 0.332, F-measure = 0.714, Accuracy = 0.991 \n",
      "2021-07-06 16:59:48,421 [INFO] utils.py/create_dir_and_delete_content | removing old model: checkpoints\\model_17200_3.43310.h5\n",
      "当前训练了第几轮 17201\n",
      "get batch time 0.0s\n",
      "forward process time 1.32e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.053s\n",
      "select_batch_time: 131.89082860946655\n",
      "2021-07-06 17:02:04,585 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17201\n",
      "2021-07-06 17:03:04,155 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 59.57s by the network, training loss = 2.390138626098633.\n",
      "当前训练了第几轮 17202\n",
      "get batch time 0.0s\n",
      "forward process time 1.4e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.078s\n",
      "select_batch_time: 140.35076093673706\n",
      "2021-07-06 17:05:24,514 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17202\n",
      "2021-07-06 17:06:22,983 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 58.47s by the network, training loss = 0.4676904082298279.\n",
      "当前训练了第几轮 17203\n",
      "get batch time 0.0s\n",
      "forward process time 1.32e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.119s\n",
      "select_batch_time: 132.2714078426361\n",
      "2021-07-06 17:08:35,256 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17203\n",
      "2021-07-06 17:09:30,500 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 55.24s by the network, training loss = 1.7966538667678833.\n",
      "当前训练了第几轮 17204\n",
      "get batch time 0.0s\n",
      "forward process time 1.26e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.145s\n",
      "select_batch_time: 125.80444717407227\n",
      "2021-07-06 17:11:36,307 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17204\n",
      "2021-07-06 17:12:30,790 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 54.48s by the network, training loss = 1.1106752157211304.\n",
      "当前训练了第几轮 17205\n",
      "get batch time 0.0s\n",
      "forward process time 1.25e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.191s\n",
      "select_batch_time: 125.49805307388306\n",
      "2021-07-06 17:14:36,290 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17205\n",
      "2021-07-06 17:15:32,779 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 56.49s by the network, training loss = 0.6333654522895813.\n",
      "当前训练了第几轮 17206\n",
      "get batch time 0.0s\n",
      "forward process time 1.35e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.215s\n",
      "select_batch_time: 135.05750250816345\n",
      "2021-07-06 17:17:47,838 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17206\n",
      "2021-07-06 17:18:45,443 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 57.60s by the network, training loss = 2.215625047683716.\n",
      "当前训练了第几轮 17207\n",
      "get batch time 0.0s\n",
      "forward process time 1.26e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.243s\n",
      "select_batch_time: 126.48328113555908\n",
      "2021-07-06 17:20:51,928 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17207\n",
      "2021-07-06 17:21:45,958 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 54.03s by the network, training loss = 0.804053008556366.\n",
      "当前训练了第几轮 17208\n",
      "get batch time 0.0s\n",
      "forward process time 1.24e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.331s\n",
      "select_batch_time: 124.29219126701355\n",
      "2021-07-06 17:23:50,252 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17208\n",
      "2021-07-06 17:24:43,897 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 53.64s by the network, training loss = 0.22756217420101166.\n",
      "当前训练了第几轮 17209\n",
      "get batch time 0.0s\n",
      "forward process time 1.24e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.361s\n",
      "select_batch_time: 125.04818964004517\n",
      "2021-07-06 17:26:48,947 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17209\n",
      "2021-07-06 17:27:42,552 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 53.60s by the network, training loss = 0.22737984359264374.\n",
      "当前训练了第几轮 17210\n",
      "get batch time 0.0s\n",
      "forward process time 1.21e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.346s\n",
      "select_batch_time: 121.48032426834106\n",
      "2021-07-06 17:29:44,035 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17210\n",
      "2021-07-06 17:30:36,234 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 52.20s by the network, training loss = 1.5680335760116577.\n",
      "Found 0000900 files with 00010 different speakers.\n",
      "2021-07-06 17:32:04,786 [INFO] <ipython-input-1-de0dd4b77245>/main | test training data EER = 0.010, F-measure = 0.941, Accuracy = 0.998 \n",
      "Found 0000900 files with 00010 different speakers.\n",
      "2021-07-06 17:33:33,731 [INFO] <ipython-input-1-de0dd4b77245>/main | == Testing model after batch #17210\n",
      "2021-07-06 17:33:33,732 [INFO] <ipython-input-1-de0dd4b77245>/main | EER = 0.014, F-measure = 0.800, Accuracy = 0.993 \n",
      "当前训练了第几轮 17211\n",
      "get batch time 0.0s\n",
      "forward process time 1.19e+02s\n",
      "beginning to select..........\n",
      "select best batch time 0.299s\n",
      "select_batch_time: 119.4749219417572\n",
      "2021-07-06 17:35:33,209 [INFO] <ipython-input-1-de0dd4b77245>/main | == Presenting step #17211\n",
      "2021-07-06 17:36:27,513 [INFO] <ipython-input-1-de0dd4b77245>/main | == Processed in 54.30s by the network, training loss = 0.5814663171768188.\n",
      "当前训练了第几轮 17212\n",
      "新训练了 11 轮,我们演示结束\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train-clean-100: 251 speaker, 28539 utterance\n",
    "# train-clean-360: 921 speaker, 104104 utterance\n",
    "# test-clean: 40 speaker, 2620 utterance\n",
    "# merged test: 80 speaker, 5323 utterance\n",
    "# batchisize 32*3 : train on triplet: 5s - > 3.1s/steps , softmax pre train: 3.1 s/steps\n",
    "\n",
    "\n",
    "import logging\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "import constants as c\n",
    "import select_batch\n",
    "from pre_process import data_catalog, preprocess_and_save\n",
    "from models import convolutional_model, convolutional_model_simple, recurrent_model\n",
    "from random_batch import stochastic_mini_batch\n",
    "from triplet_loss import deep_speaker_loss\n",
    "from utils import get_last_checkpoint_if_any, create_dir_and_delete_content\n",
    "from test_model import eval_model\n",
    "\n",
    "#创建语音和朗读者的对应关系字典\n",
    "def create_dict(files,labels,spk_uniq):\n",
    "    train_dict = {}\n",
    "    for i in range(len(spk_uniq)):\n",
    "        train_dict[spk_uniq[i]] = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        train_dict[labels[i]].append(files[i])\n",
    "\n",
    "    for spk in spk_uniq:\n",
    "        if len(train_dict[spk]) < 2:\n",
    "            train_dict.pop(spk)\n",
    "    unique_speakers=list(train_dict.keys())\n",
    "    return train_dict, unique_speakers\n",
    "\n",
    "#训练主函数\n",
    "def main(libri_dir=c.DATASET_DIR):\n",
    "\n",
    "    PRE_TRAIN = c.PRE_TRAIN\n",
    "    logging.info('Looking for fbank features [.npy] files in {}.'.format(libri_dir))\n",
    "    libri = data_catalog(libri_dir) # 读取全部的npy文件.\n",
    "\n",
    "    if len(libri) == 0:\n",
    "        logging.warning('Cannot find npy files, we will load audio, extract features and save it as npy file')\n",
    "        logging.warning('Waiting for preprocess...')\n",
    "        preprocess_and_save(c.WAV_DIR, c.DATASET_DIR)\n",
    "        libri = data_catalog(libri_dir)\n",
    "        if len(libri) == 0:\n",
    "            logging.warning('Have you converted flac files to wav? If not, run audio/convert_flac_2_wav.sh')\n",
    "            exit(1)\n",
    "    unique_speakers = libri['speaker_id'].unique()\n",
    "    spk_utt_dict, unique_speakers = create_dict(libri['filename'].values,libri['speaker_id'].values,unique_speakers)\n",
    "    select_batch.create_data_producer(unique_speakers, spk_utt_dict) # 创建数据集,  音频 和对应的用户id作为label\n",
    "\n",
    "    #创建batch\n",
    "    batch = stochastic_mini_batch(libri, batch_size=c.BATCH_SIZE, unique_speakers=unique_speakers)\n",
    "    batch_size = c.BATCH_SIZE * c.TRIPLET_PER_BATCH #一个batch 有96个元素.\n",
    "    x, y = batch.to_inputs()\n",
    "    b = x[0]\n",
    "    num_frames = b.shape[0] # 每个元素 是160帧, 每一帧特征64维度\n",
    "    train_batch_size = batch_size\n",
    "    #batch_shape = [batch_size * num_frames] + list(b.shape[1:])  # A triplet has 3 parts.\n",
    "    input_shape = (num_frames, b.shape[1], b.shape[2])\n",
    "\n",
    "    logging.info('num_frames = {}'.format(num_frames))\n",
    "    logging.info('batch size: {}'.format(batch_size))\n",
    "    logging.info('input shape: {}'.format(input_shape))\n",
    "    logging.info('x.shape : {}'.format(x.shape))\n",
    "    orig_time = time()\n",
    "    #搭建网络结构\n",
    "    model = convolutional_model(input_shape=input_shape, batch_size=batch_size, num_frames=num_frames)\n",
    "    logging.info(model.summary())\n",
    "    gru_model = None\n",
    "    if c.COMBINE_MODEL: # 另外一种网络gru.这里我们不用.\n",
    "        gru_model = recurrent_model(input_shape=input_shape, batch_size=batch_size, num_frames=num_frames)\n",
    "        logging.info(gru_model.summary())\n",
    "    grad_steps = 0\n",
    "    # 是否读取预训练模型.\n",
    "    if PRE_TRAIN:#我们不加载预训练\n",
    "        last_checkpoint = get_last_checkpoint_if_any(c.PRE_CHECKPOINT_FOLDER)\n",
    "        if last_checkpoint is not None:\n",
    "            logging.info('Found pre-training checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
    "            x = model.output\n",
    "            x = Dense(len(unique_speakers), activation='softmax', name='softmax_layer')(x)\n",
    "            pre_model = Model(model.input, x)\n",
    "            pre_model.load_weights(last_checkpoint)\n",
    "            grad_steps = int(last_checkpoint.split('_')[-2])\n",
    "            logging.info('Successfully loaded pre-training model')\n",
    "\n",
    "    else:# 我们直接加载最后checkpoint即可.\n",
    "        last_checkpoint = get_last_checkpoint_if_any(c.CHECKPOINT_FOLDER)\n",
    "        if last_checkpoint is not None:\n",
    "            logging.info('Found checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
    "            print(\"加载了模型\",last_checkpoint)\n",
    "            model.load_weights(last_checkpoint)\n",
    "            grad_steps = int(last_checkpoint.split('_')[-2])\n",
    "            logging.info('[DONE]')\n",
    "        if c.COMBINE_MODEL:\n",
    "            last_checkpoint = get_last_checkpoint_if_any(c.GRU_CHECKPOINT_FOLDER)\n",
    "            if last_checkpoint is not None:\n",
    "                logging.info('Found checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
    "                gru_model.load_weights(last_checkpoint)\n",
    "                logging.info('[DONE]')\n",
    "\n",
    "    #adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer='adam', loss=deep_speaker_loss)\n",
    "    if c.COMBINE_MODEL:\n",
    "        gru_model.compile(optimizer='adam', loss=deep_speaker_loss)\n",
    "    print(\"model_build_time\",time()-orig_time)\n",
    "    logging.info('Starting training...')\n",
    "    lasteer = 10\n",
    "    eer = 1\n",
    "    epoch=0\n",
    "    while True:\n",
    "        orig_time = time()\n",
    "        x, _ = select_batch.best_batch(model, batch_size=c.BATCH_SIZE)# 构造batch数据.\n",
    "        print(\"select_batch_time:\", time() - orig_time)\n",
    "        y = np.random.uniform(size=(x.shape[0], 1)) # 来个随机数,因为我们的任务根本不需要target. 属于一个非监督学习.为了套下面的train_on_batch函数.所以随机给个y即可.对结果无影响.\n",
    "        logging.info('== Presenting step #{0}'.format(grad_steps))\n",
    "        orig_time = time()\n",
    "        loss = model.train_on_batch(x, y)\n",
    "        logging.info('== Processed in {0:.2f}s by the network, training loss = {1}.'.format(time() - orig_time, loss))\n",
    "        if c.COMBINE_MODEL:\n",
    "            loss1 = gru_model.train_on_batch(x, y)\n",
    "            logging.info( '== Processed in {0:.2f}s by the gru-network, training loss = {1}.'.format(time() - orig_time, loss1))\n",
    "            with open(c.GRU_CHECKPOINT_FOLDER + '/losses_gru.txt', \"a\") as f:\n",
    "                f.write(\"{0},{1}\\n\".format(grad_steps, loss1))\n",
    " # record training loss#============记录loss信息\n",
    "        with open(c.LOSS_LOG, \"a\") as f:\n",
    "            f.write(\"{0},{1}\\n\".format(grad_steps, loss))\n",
    "        if (grad_steps) % 10 == 0:#训练集上面进行测试\n",
    "            fm1, tpr1, acc1, eer1 = eval_model(model, train_batch_size, test_dir=c.DATASET_DIR, check_partial=True, gru_model=gru_model)\n",
    "            logging.info('test training data EER = {0:.3f}, F-measure = {1:.3f}, Accuracy = {2:.3f} '.format(eer1, fm1, acc1))\n",
    "            with open(c.CHECKPOINT_FOLDER + '/train_acc_eer.txt', \"a\") as f:\n",
    "                f.write(\"{0},{1},{2},{3}\\n\".format(grad_steps, eer1, fm1, acc1))\n",
    "#====评估模型.\n",
    "        if (grad_steps ) % c.TEST_PER_EPOCHS == 0 : #测试集上进行测试.所以这个指标才真正有价值\n",
    "            fm, tpr, acc, eer = eval_model(model,train_batch_size, test_dir=c.TEST_DIR,gru_model=gru_model)\n",
    "            logging.info('== Testing model after batch #{0}'.format(grad_steps))\n",
    "            logging.info('EER = {0:.3f}, F-measure = {1:.3f}, Accuracy = {2:.3f} '.format(eer, fm, acc))\n",
    "            with open(c.TEST_LOG, \"a\") as f:\n",
    "                f.write(\"{0},{1},{2},{3}\\n\".format(grad_steps, eer, fm, acc))\n",
    "#==保存模型.\n",
    "        # checkpoints are really heavy so let's just keep the last one.\n",
    "        if (grad_steps ) % c.SAVE_PER_EPOCHS == 0: # 每200个epoch保存一下模型.\n",
    "            create_dir_and_delete_content(c.CHECKPOINT_FOLDER)\n",
    "            model.save_weights('{0}/model_{1}_{2:.5f}.h5'.format(c.CHECKPOINT_FOLDER, grad_steps, loss))\n",
    "\n",
    "\n",
    "        grad_steps += 1\n",
    "        print(\"当前训练了第几轮\",grad_steps)\n",
    "        #==============这里面我们为了展示.所以设置了grad_steps的最大值就停止了.\n",
    "        if epoch==11:\n",
    "            print(\"新训练了\",epoch,\"轮,我们演示结束\")\n",
    "            break\n",
    "        epoch+=1\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(handlers=[logging.StreamHandler(stream=sys.stdout)], level=logging.INFO,\n",
    "                        format='%(asctime)-15s [%(levelname)s] %(filename)s/%(funcName)s | %(message)s')\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
