{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#脚本是在测试集上面进行测试. 训练代码里面已经调用了这部分代码.\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "import constants as c\n",
    "from pre_process import data_catalog, preprocess_and_save\n",
    "from eval_metrics import evaluate\n",
    "from models import convolutional_model, recurrent_model\n",
    "from triplet_loss import deep_speaker_loss\n",
    "from utils import get_last_checkpoint_if_any, create_dir_and_delete_content\n",
    "import tensorflow as tf\n",
    "\n",
    "num_neg = c.TEST_NEGATIVE_No\n",
    "\n",
    "def normalize_scores(m,epsilon=1e-12):\n",
    "    return (m - np.mean(m)) / max(np.std(m),epsilon)\n",
    "\n",
    "def clipped_audio(x, num_frames=c.NUM_FRAMES):\n",
    "    if x.shape[0] > num_frames + 20:\n",
    "        bias = np.random.randint(20, x.shape[0] - num_frames)\n",
    "        clipped_x = x[bias: num_frames + bias]\n",
    "    elif x.shape[0] > num_frames:\n",
    "        bias = np.random.randint(0, x.shape[0] - num_frames)\n",
    "        clipped_x = x[bias: num_frames + bias]\n",
    "    else:\n",
    "        clipped_x = x\n",
    "\n",
    "    return clipped_x\n",
    "\n",
    "def create_test_data(test_dir,check_partial):\n",
    "    global num_neg\n",
    "    libri = data_catalog(test_dir)\n",
    "    unique_speakers = list(libri['speaker_id'].unique())\n",
    "    np.random.shuffle(unique_speakers)\n",
    "    num_triplets = len(unique_speakers)\n",
    "    if check_partial:\n",
    "        num_neg = 49; num_triplets = min(num_triplets, 30)\n",
    "    test_batch = None\n",
    "    for ii in range(num_triplets):\n",
    "        anchor_positive_file = libri[libri['speaker_id'] == unique_speakers[ii]]\n",
    "        if len(anchor_positive_file) <2:\n",
    "            continue\n",
    "        anchor_positive_file = anchor_positive_file.sample(n=2, replace=False)\n",
    "        anchor_df = pd.DataFrame(anchor_positive_file[0:1])\n",
    "        anchor_df['training_type'] = 'ancfrom thor'                      # 1 anchor，1 positive，num_neg negative\n",
    "        if test_batch is None:\n",
    "            test_batch = anchor_df.copy()\n",
    "        else:\n",
    "            test_batch = pd.concat([test_batch, anchor_df], axis=0)\n",
    "\n",
    "        positive_df = pd.DataFrame(anchor_positive_file[1:2])\n",
    "        positive_df['training_type'] = 'positive'\n",
    "        test_batch = pd.concat([test_batch, positive_df], axis=0)\n",
    "\n",
    "        negative_files = libri[libri['speaker_id'] != unique_speakers[ii]].sample(n=num_neg, replace=False)\n",
    "        for index in range(len(negative_files)):\n",
    "            negative_df = pd.DataFrame(negative_files[index:index+1])\n",
    "            negative_df['training_type'] = 'negative'\n",
    "            test_batch = pd.concat([test_batch, negative_df], axis=0)\n",
    "\n",
    "    new_x = []\n",
    "    for i in range(len(test_batch)):\n",
    "        filename = test_batch[i:i + 1]['filename'].values[0]\n",
    "        x = np.load(filename)\n",
    "        new_x.append(clipped_audio(x))\n",
    "    x = np.array(new_x)  # (batchsize, num_frames, 64, 1)\n",
    "    new_y = np.hstack(([1], np.zeros(num_neg)))  # 1 positive, num_neg negative\n",
    "    y = np.tile(new_y, num_triplets)\n",
    "    return x, y\n",
    "\n",
    "def batch_cosine_similarity(x1, x2):\n",
    "    # https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "    # 1 = equal direction ; -1 = opposite direction\n",
    "    mul = np.multiply(x1, x2)\n",
    "    s = np.sum(mul,axis=1)\n",
    "\n",
    "    #l1 = np.sum(np.multiply(x1, x1),axis=1)\n",
    "    #l2 = np.sum(np.multiply(x2, x2), axis=1)\n",
    "    # as values have have length 1, we don't need to divide by norm (as it is 1)\n",
    "    return s\n",
    "\n",
    "def call_similar(x):\n",
    "    no_batch = int(x.shape[0] / (num_neg+2))  # each batch was consisted of 1 anchor ,1 positive , num_neg negative, so the number of batch\n",
    "    similar = []\n",
    "    for ep in range(no_batch):\n",
    "        index = ep*(num_neg + 2)\n",
    "        anchor = np.tile(x[index], (num_neg + 1, 1))\n",
    "        pos_neg = x[index+1: index + num_neg + 2]\n",
    "        sim = batch_cosine_similarity(anchor, pos_neg)\n",
    "        similar.extend(sim)\n",
    "    return np.array(similar)\n",
    "\n",
    "def eval_model(model,train_batch_size=c.BATCH_SIZE * c.TRIPLET_PER_BATCH, test_dir= c.TEST_DIR, check_partial=False, gru_model=None):\n",
    "    x, y_true = create_test_data(test_dir,check_partial)\n",
    "    batch_size = x.shape[0]\n",
    "    b = x[0]\n",
    "    num_frames = b.shape[0]\n",
    "    input_shape = (num_frames, b.shape[1], b.shape[2])\n",
    "\n",
    "    '''\n",
    "    print('test_data:')\n",
    "    print('num_frames = {}'.format(num_frames))\n",
    "    print('batch size: {}'.format(batch_size))\n",
    "    print('input shape: {}'.format(input_shape))\n",
    "    print('x.shape before reshape: {}'.format(x.shape))\n",
    "    print('x.shape after  reshape: {}'.format(x.shape))\n",
    "    print('y.shape: {}'.format(y_true.shape))\n",
    "    '''\n",
    "    #embedding = model.predict_on_batch(x)\n",
    "    test_epoch = int(len(y_true)/train_batch_size)\n",
    "    embedding = None\n",
    "    for ep in range(test_epoch):\n",
    "        x_ = x[ep*train_batch_size: (ep + 1)*train_batch_size]\n",
    "        embed = model.predict_on_batch(x_) # 模型传入数据,输出每个数据的表示向量.我们以后使用这个模型就是给一个音频然后得到embeddign vector然后比较向量余弦相似度即可.\n",
    "        if embedding is None:\n",
    "            embedding = embed.copy()\n",
    "        else:\n",
    "            embedding = np.concatenate([embedding, embed], axis=0)\n",
    "    y_pred = call_similar(embedding) # 计算相似度\n",
    "    if gru_model is not None:\n",
    "        embedding_gru = None\n",
    "        for ep in range(test_epoch):\n",
    "            x_ = x[ep * train_batch_size: (ep + 1) * train_batch_size]\n",
    "            embed = model.predict_on_batch(x_)\n",
    "            if embedding_gru is None:\n",
    "                embedding_gru = embed.copy()\n",
    "            else:\n",
    "                embedding_gru = np.concatenate([embedding_gru, embed], axis=0)\n",
    "        y_pred_gru = call_similar(embedding_gru)\n",
    "\n",
    "        y_pred = (normalize_scores(y_pred) + normalize_scores(y_pred_gru))/2  # or   y_pred = (y_pred + y_pred_gru)/2\n",
    "\n",
    "    nrof_pairs = min(len(y_pred), len(y_true))\n",
    "    y_pred = y_pred[:nrof_pairs]\n",
    "    y_true = y_true[:nrof_pairs]\n",
    "    fm, tpr, acc, eer = evaluate(y_pred, y_true) # 计算指标. 给2个相似矩阵然后计算指标即可.\n",
    "    return fm, tpr, acc, eer\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = convolutional_model()\n",
    "    gru_model = None\n",
    "    last_checkpoint = get_last_checkpoint_if_any(c.CHECKPOINT_FOLDER)\n",
    "    if last_checkpoint is not None:\n",
    "        print('Found checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
    "        model.load_weights(last_checkpoint)\n",
    "    if c.COMBINE_MODEL:\n",
    "        gru_model = recurrent_model()\n",
    "        last_checkpoint = get_last_checkpoint_if_any(c.GRU_CHECKPOINT_FOLDER)\n",
    "        if last_checkpoint is not None:\n",
    "            print('Found checkpoint [{}]. Resume from here...'.format(last_checkpoint))\n",
    "            gru_model.load_weights(last_checkpoint)\n",
    "\n",
    "    fm, tpr, acc, eer = eval_model(model, check_partial=True,gru_model=gru_model)\n",
    "    print(\"f-measure = {0}, true positive rate = {1}, accuracy = {2}, equal error rate = {3}\".format(fm, tpr, acc, eer))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
