{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们安装好anaconda  https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.0.0-Windows-x86_64.exe\n",
    "\n",
    "之后进行python第三方库包的安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Requirement already satisfied: pip in e:\\anaconda3\\lib\\site-packages (21.1.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Requirement already satisfied: python_speech_features in e:\\anaconda3\\lib\\site-packages (0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\appdata\\roaming\\python\\python36\\site-packages (1.1.0)\n",
      "Collecting scipy\n",
      "  Downloading http://pypi.doubanio.com/packages/f3/9f/80522344838ae24cac9e945240436269cbb92349f7f1f4c9dfc10cb6bad5/scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in e:\\anaconda3\\lib\\site-packages (from scipy) (1.19.5)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.1.0\n",
      "    Uninstalling scipy-1.1.0:\n",
      "      Successfully uninstalled scipy-1.1.0\n",
      "Successfully installed scipy-1.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install  --upgrade scipy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install  scikit-learn==0.16.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install  sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Requirement already satisfied: numpy in e:\\anaconda3\\lib\\site-packages (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install   numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0000899 files with 00010 different speakers.\n",
      "extract fbank from audio and save as npy, using multiprocessing pool........ \n",
      "task 0 slibri length: 179\n",
      "task 1 slibri length: 179\n",
      "task 2 slibri length: 179\n",
      "task 3 slibri length: 179\n",
      "task 4 slibri length: 183\n",
      "Waiting for all subprocesses done...\n"
     ]
    }
   ],
   "source": [
    "# extract fbanck from flac and save to file 从flac文件中抽取非空白文件然后存成npz文件.\n",
    "# pre processd an audio in 0.09912s\n",
    "\n",
    "# jupyter 不支持多进程会卡死所以需要用文件调用, 所以用下面运行py文件的方法来运行.\n",
    "%%writefile temp\\1.py\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from python_speech_features import fbank, delta\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import silence_detector\n",
    "import constants as c\n",
    "from constants import SAMPLE_RATE\n",
    "from time import time\n",
    "import sys\n",
    "# np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "\n",
    "\n",
    "def find_files(directory, pattern='**/*.flac'):\n",
    "    \"\"\"Recursively finds all files matching the pattern.\"\"\"\n",
    "    return glob(os.path.join(directory, pattern), recursive=True)\n",
    "#\n",
    "def VAD(audio):\n",
    "    chunk_size = int(SAMPLE_RATE*0.05) # 50ms\n",
    "    index = 0\n",
    "    sil_detector = silence_detector.SilenceDetector(15)\n",
    "    nonsil_audio=[]\n",
    "    while index + chunk_size < len(audio):\n",
    "        if not sil_detector.is_silence(audio[index: index+chunk_size]): # 不是静音片段就记录下来.\n",
    "            nonsil_audio.extend(audio[index: index + chunk_size])\n",
    "        index += chunk_size\n",
    "\n",
    "    return np.array(nonsil_audio)\n",
    "\n",
    "def read_audio(filename, sample_rate=SAMPLE_RATE):\n",
    "    audio, sr = librosa.load(filename, sr=sample_rate, mono=True)\n",
    "    audio = VAD(audio.flatten())\n",
    "    start_sec, end_sec = c.TRUNCATE_SOUND_SECONDS\n",
    "    start_frame = int(start_sec * SAMPLE_RATE)\n",
    "    end_frame = int(end_sec * SAMPLE_RATE)\n",
    "\n",
    "    if len(audio) < (end_frame - start_frame):\n",
    "        au = [0] * (end_frame - start_frame)\n",
    "        for i in range(len(audio)):\n",
    "            au[i] = audio[i]\n",
    "        audio = np.array(au)\n",
    "    return audio\n",
    "\n",
    "def normalize_frames(m,epsilon=1e-12):\n",
    "    return [(v - np.mean(v)) / max(np.std(v),epsilon) for v in m]\n",
    "\n",
    "def extract_features(signal=np.random.uniform(size=48000), target_sample_rate=SAMPLE_RATE):\n",
    "    filter_banks, energies = fbank(signal, samplerate=target_sample_rate, nfilt=64, winlen=0.025)   #filter_bank (num_frames , 64),energies (num_frames ,)\n",
    "    #delta_1 = delta(filter_banks, N=1)\n",
    "    #delta_2 = delta(delta_1, N=1)\n",
    "\n",
    "    filter_banks = normalize_frames(filter_banks)\n",
    "    #delta_1 = normalize_frames(delta_1)\n",
    "    #delta_2 = normalize_frames(delta_2)\n",
    "\n",
    "    #frames_features = np.hstack([filter_banks, delta_1, delta_2])    # (num_frames , 192)\n",
    "    frames_features = filter_banks     # (num_frames , 64)\n",
    "    num_frames = len(frames_features)\n",
    "    return np.reshape(np.array(frames_features),(num_frames, 64, 1))   #(num_frames,64, 1)\n",
    "\n",
    "def data_catalog(dataset_dir=c.DATASET_DIR, pattern='*.npy'):\n",
    "    libri = pd.DataFrame()\n",
    "    libri['filename'] = find_files(dataset_dir, pattern=pattern)\n",
    "    libri['filename'] = libri['filename'].apply(lambda x: x.replace('\\\\', '/'))  # normalize windows paths\n",
    "    libri['speaker_id'] = libri['filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n",
    "    num_speakers = len(libri['speaker_id'].unique())\n",
    "    print('Found {} files with {} different speakers.'.format(str(len(libri)).zfill(7), str(num_speakers).zfill(5)))\n",
    "    # print(libri.head(10))\n",
    "    return libri\n",
    "\n",
    "def prep(libri,out_dir=c.DATASET_DIR,name='0'):\n",
    "    start_time = time()\n",
    "    i=0\n",
    "    for i in range(len(libri)):\n",
    "        orig_time = time()\n",
    "        filename = libri[i:i+1]['filename'].values[0]\n",
    "        target_filename = out_dir + filename.split(\"/\")[-1].split('.')[0] + '.npy'\n",
    "        if os.path.exists(target_filename):# 已经处理过了,就continue\n",
    "            if i % 10 == 0: print(\"task:{0} No.:{1} Exist File:{2}\".format(name, i, filename))\n",
    "            continue\n",
    "        raw_audio = read_audio(filename)\n",
    "        feature = extract_features(raw_audio, target_sample_rate=SAMPLE_RATE)\n",
    "        if feature.ndim != 3 or feature.shape[0] < c.NUM_FRAMES or feature.shape[1] !=64 or feature.shape[2] != 1:\n",
    "            print('there is an error in file:',filename)\n",
    "            continue\n",
    "        np.save(target_filename, feature)\n",
    "        if i % 100 == 0:\n",
    "            print(\"task:{0} cost time per audio: {1:.3f}s No.:{2} File name:{3}\".format(name, time() - orig_time, i, filename))\n",
    "    print(\"task %s runs %d seconds. %d files\" %(name, time()-start_time,i))\n",
    "\n",
    "#使用多进程跑.\n",
    "def preprocess_and_save(wav_dir=c.WAV_DIR,out_dir=c.DATASET_DIR):\n",
    "\n",
    "    orig_time = time()\n",
    "    libri = data_catalog(wav_dir, pattern='**/*.flac')  #'/Users/walle/PycharmProjects/Speech/coding/deep-speaker-master/audio/LibriSpeechSamples/train-clean-100/19'\n",
    "\n",
    "    print(\"extract fbank from audio and save as npy, using multiprocessing pool........ \")\n",
    "    p = Pool(5)\n",
    "    patch = int(len(libri)/5)\n",
    "    for i in range(5):\n",
    "        if i < 4:\n",
    "            slibri=libri[i*patch: (i+1)*patch] #切分数据集.给每一个进程.\n",
    "        else:\n",
    "            slibri = libri[i*patch:]\n",
    "        print(\"task %s slibri length: %d\" %(i, len(slibri)))\n",
    "        p.apply_async(prep, args=(slibri,out_dir,i)) #调用上面prep函数\n",
    "    print('Waiting for all subprocesses done...')\n",
    "    p.close() # 关闭进程池（pool），使其不再接受新的任务\n",
    "    p.join()   # 主进程阻塞等待子进程的退出  这2行是多进程的固定写法.\n",
    "\n",
    "    print(\"Extract audio features and save it as npy file, cost {0} seconds\".format(time()-orig_time))\n",
    "    print(\"*^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*  *^ˍ^*\")\n",
    "\n",
    "\n",
    "def Fortest():#这是一个信息抽取函数的测试.可以自己调用来测试.\n",
    "    libri = data_catalog()\n",
    "    filename = 'audio/LibriSpeechSamples/train-clean-100/19/227/19-227-0036.wav'\n",
    "    raw_audio = read_audio(filename)\n",
    "    print(filename)\n",
    "    feature = extract_features(raw_audio, target_sample_rate=SAMPLE_RATE)\n",
    "    print(filename)\n",
    "if 0:#这个部分打开,可以测试一下读取flac和wav文件的结果是一样的.\n",
    "    a=librosa.load('19-198-0000.flac', sr=SAMPLE_RATE, mono=True)\n",
    "    b=librosa.load('19-198-0000.wav', sr=SAMPLE_RATE, mono=True)\n",
    "    print(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #test()\n",
    "    preprocess_and_save(\"audio/LibriSpeechSamples/train-clean-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! temp\\1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
