{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、模型训练、测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **模型训练**\n",
    "模型训练代码为 ```bert_lesson_model.ipynb```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 设置模型输入**  \n",
    "如代码，每条数据数据有两个句子输入，每个句子会被转化为对应的格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "the_feature = {\n",
    "        \"input_ids_a\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_ids_a'),\n",
    "        \"input_ids_b\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_ids_b'),\n",
    "        \"input_mask_a\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_mask_a'),\n",
    "        \"input_mask_b\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_mask_b'),\n",
    "        \"seg_ids_a\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='seg_ids_a'),\n",
    "        \"seg_ids_b\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='seg_ids_b')\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 设置损失函数**  \n",
    "上一节中提到的损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "loss_op = net(the_feature,256,True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 设置优化方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处采用Adam（Adaptive Moment Estimation）优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "train_op = tf.train.AdamOptimizer(cfg.learning_rate).minimize(loss_op)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 从BERT预训练模型中导入网络结构和参数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cfg.init_checkpoint中存放着BERT预训练模型；tvars为需要训练的tensor  \n",
    "```python \n",
    "(assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, cfg.init_checkpoint)\n",
    "tf.train.init_from_checkpoint(cfg.init_checkpoint, assignment_map)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. 开始训练**  \n",
    "（1）函数```get_data_batch_auto()```获取一个batch的数据，feed进模型中  \n",
    "（2）根据前文设置的损失函数和优化方法进行训练：```    _, loss_value = sess.run([train_op,loss_op],feed)```  \n",
    "（3）若干步骤后保存一次模型：```saver.save(sess, os.path.join(cfg.output_dir, model_name + '.ckpt')) ```  \n",
    "注，ckpt格式的文件说明：  \n",
    "&emsp;&emsp;checkpoint文件：b包含最新的和所有的文件地址  \n",
    "&emsp;&emsp;.data文件：包含训练变量的文件  \n",
    "&emsp;&emsp;.index文件：描述variable中key和value的对应关系  \n",
    "&emsp;&emsp;.meta文件：保存完整的网络图结构  \n",
    "使用这种方法保存模型时会保存成上面这四个文件，重新加载模型时通常只会用到.meta文件恢复图结构然后用.data文件把各个变量的值再加进去。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "# 循环次数视loss值以及模型测试效果进行增减\n",
    "for idx in range(3000):\n",
    "    # 获取一个batch的数据\n",
    "    temp_features = get_data_batch_auto(left_array_pos,right_array_pos,left_array_neg,right_array_neg,batch_num,tokenizer)\n",
    "    feed = {\n",
    "            the_feature[\"input_ids_a\"]:temp_features[\"input_ids_a\"],\n",
    "            the_feature[\"input_ids_b\"]:temp_features[\"input_ids_b\"],\n",
    "            the_feature[\"input_mask_a\"]:temp_features[\"input_mask_a\"],\n",
    "            the_feature[\"input_mask_b\"]:temp_features[\"input_mask_b\"],\n",
    "            the_feature[\"seg_ids_a\"]:temp_features[\"seg_ids_a\"],\n",
    "            the_feature[\"seg_ids_b\"]:temp_features[\"seg_ids_b\"]\n",
    "            }\n",
    "    \n",
    "    # 开启训练\n",
    "    _, loss_value = sess.run([train_op,loss_op],feed)\n",
    "    \n",
    "    # 打印loss\n",
    "    print (idx,loss_value)\n",
    "    if (idx % 100 == 0 and idx != 0):\n",
    "        saver.save(sess, os.path.join(cfg.output_dir, model_name + '.ckpt'))\n",
    "    if loss_value < 0.0001:\n",
    "        saver.save(sess, os.path.join(cfg.output_dir, model_name + '.ckpt'))\n",
    "        break\n",
    "        \n",
    "    # 刷新本cell的输出\n",
    "    ipd.clear_output(wait=True)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **保存pb格式模型**  \n",
    "保存pb模型的代码在save_and_eval.ipynb  \n",
    "注：.pb文件里面保存了图结构+数据，加载模型时只需要这一个文件就好  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数：```freeze_graph()```  \n",
    "  \n",
    "参数：```ckpt:ckpt格式模型的位置```  \n",
    "&emsp;&emsp;&emsp;```output_graph:pb模型的存储位置及名字```  \n",
    "  \n",
    "返回：```无```  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **执行实验**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入相关模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from random import shuffle, sample\n",
    "from data_input import load_raw_data, get_data_batch_auto  # 数据预处理\n",
    "import tokenization\n",
    "from config import Config as cfg  \n",
    "from model_for_chatbot import net   # 模型\n",
    "import modeling\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置本实验演示过程中的临时参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = cfg.train_batch_size\n",
    "model_name = cfg.model_name\n",
    "output_dir = './exercise/output'\n",
    "release_dir = './exercise/release'\n",
    "\n",
    "# 设置GPU显存可灵活增长\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "sess = tf.Session(config=config) \n",
    "model_name = cfg.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files:./raw_data/chatbot_neg.tsv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "left_array_pos, right_array_pos = load_raw_data(model_name+'_pos.tsv')\n",
    "#neg file is not necessary, default is blank list\n",
    "left_array_neg = []\n",
    "right_array_neg = []\n",
    "left_array_neg, right_array_neg = load_raw_data(model_name+'_neg.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_feature = {\n",
    "        \"input_ids_a\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_ids_a'),\n",
    "        \"input_ids_b\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_ids_b'),\n",
    "        \"input_mask_a\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_mask_a'),\n",
    "        \"input_mask_b\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='input_mask_b'),\n",
    "        \"seg_ids_a\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='seg_ids_a'),\n",
    "        \"seg_ids_b\":tf.placeholder(tf.int32, [None,cfg.max_seq_length], name='seg_ids_b')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置模型结构，优化方法，以及损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/yxt_work/chatbot/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/yxt_work/chatbot/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /data/yxt_work/chatbot/modeling.py:687: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/tf1.14/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fc0fe0f236d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0massignment_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialized_variable_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_assignment_map_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_map\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 从预训练模型中初始化模型结构和模型参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "loss_op = net(the_feature,256,False)    # 设置模型损失函数\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(cfg.learning_rate).minimize(loss_op)#,global_step=global_step)   # 设置模型优化方法\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "(assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, cfg.init_checkpoint)\n",
    "tf.train.init_from_checkpoint(cfg.init_checkpoint, assignment_map)  # 从预训练模型中初始化模型结构和模型参数\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 执行模型训练步骤（演示）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3b9297947eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 执行训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenization.FullTokenizer(vocab_file='./model/vocab.txt', do_lower_case=True)\n",
    "\n",
    "for idx in range(10):\n",
    "    # 获得一个batch的数据\n",
    "    temp_features = get_data_batch_auto(left_array_pos,right_array_pos,left_array_neg,right_array_neg,batch_num,tokenizer)\n",
    "    \n",
    "    # 将数据喂到设置好的模型输入place_hold中\n",
    "    feed = {\n",
    "            the_feature[\"input_ids_a\"]:temp_features[\"input_ids_a\"],\n",
    "            the_feature[\"input_ids_b\"]:temp_features[\"input_ids_b\"],\n",
    "            the_feature[\"input_mask_a\"]:temp_features[\"input_mask_a\"],\n",
    "            the_feature[\"input_mask_b\"]:temp_features[\"input_mask_b\"],\n",
    "            the_feature[\"seg_ids_a\"]:temp_features[\"seg_ids_a\"],\n",
    "            the_feature[\"seg_ids_b\"]:temp_features[\"seg_ids_b\"]\n",
    "            }\n",
    "    \n",
    "    # 执行训练\n",
    "    _, loss_value = sess.run([train_op,loss_op],feed)\n",
    "    print (idx,loss_value)\n",
    "    if (idx % 1000 == 0 and idx != 0):        \n",
    "        saver.save(sess, os.path.join(output_dir, model_name + '.ckpt'))\n",
    "    if loss_value < 0.00001:\n",
    "        saver.save(sess, os.path.join(output_dir, model_name + '.ckpt'))\n",
    "        break\n",
    "    ipd.clear_output(wait=True)\n",
    "\n",
    "# 训练结束， 保存ckpt模型文件\n",
    "saver.save(sess, os.path.join(output_dir, model_name + '.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将模型保存为pb格式以便调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "tf.reset_default_graph() \n",
    "def freeze_graph(ckpt, output_graph):\n",
    "    output_node_names = 'MatMul'\n",
    "    saver = tf.compat.v1.train.import_meta_graph(ckpt+'.meta', clear_devices=True)\n",
    "    graph = tf.get_default_graph()\n",
    "    input_graph_def = graph.as_graph_def()\n",
    " \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, ckpt)\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "            sess=sess,\n",
    "            input_graph_def=input_graph_def,\n",
    "            output_node_names=output_node_names.split(',')\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as fw:\n",
    "            fw.write(output_graph_def.SerializeToString())\n",
    "        print ('{} ops in the final graph.'.format(len(output_graph_def.node)))\n",
    "\n",
    "freeze_graph(output_dir + '/' + model_name + '.ckpt', release_dir +'/' + model_name + '.pb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.14",
   "language": "python",
   "name": "tf1.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
